{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***PARTE DE PYTHON DE LA PRÁCTICA NÚMERO DOS DE DATOS***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1) PREPARACIONES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "titanicTraindata = pd.read_csv(\"train.csv\",quotechar='\"') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Veamos la estructura de la tabla en Python\n",
    "\n",
    "print (titanicTraindata.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Survived         0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age            177\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             0\n",
       "Cabin          687\n",
       "Embarked         2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encontramos el número de variables (columnas del DataFrame) que contienen NA\n",
    "\n",
    "# La cantidad por columnas es:\n",
    "\n",
    "titanicTraindata.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
       "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
       "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
       "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
       "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
       "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
       "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
       "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
       "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
       "\n",
       "            Parch        Fare  \n",
       "count  891.000000  891.000000  \n",
       "mean     0.381594   32.204208  \n",
       "std      0.806057   49.693429  \n",
       "min      0.000000    0.000000  \n",
       "25%      0.000000    7.910400  \n",
       "50%      0.000000   14.454200  \n",
       "75%      0.000000   31.000000  \n",
       "max      6.000000  512.329200  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanicTraindata.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(2) IMPUTACIONES DE VALORES PERDIDOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891,)\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 70 71 74 80]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import KNNImputer as KNNIM\n",
    "\n",
    "# Creamos un DF auxuliar con los campos numéricos que nos permitan hacer una imputación por distancia euclidea\n",
    "aux_df = titanicTraindata[['Age','Pclass','SibSp','Parch','Fare']]\n",
    "\n",
    "imputer = KNNIM(n_neighbors=3)\n",
    "aux_df2 = imputer.fit_transform(aux_df)\n",
    "\n",
    "nueva_age = (    (aux_df2[:,0])  )\n",
    "\n",
    "print (nueva_age.shape)\n",
    "\n",
    "# Redondeamos las fechas a la parte entera de la edad.\n",
    "nueva_age = nueva_age.astype(int)\n",
    "\n",
    "print (np.unique(nueva_age))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "titanicTraindata[['Age']] = (nueva_age)\n",
    "\n",
    "# Para el valor Embartked asignamos el valor más comun = \"S\"\n",
    "\n",
    "titanicTraindata[['Embarked']] = titanicTraindata[['Embarked']].fillna('S')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(3) DETERMINACIÓN OUTLIERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encontramos los outliers\n",
    "\n",
    "# Q3 +1.5⋅IQR\n",
    "# Q1 −1.5⋅IQR\n",
    "\n",
    "def limites_outliers (x):\n",
    "    Q3 = np.percentile(x, 75)\n",
    "    Q1 = np.percentile(x, 75)\n",
    "    IQR = np.subtract(np.percentile(x, 75),np.percentile(x, 25))\n",
    "    lim_inf = Q1 - 1.5 *IQR\n",
    "    lim_sup = Q3 + 1.5 *IQR\n",
    "    resultado = (lim_inf,lim_sup)               \n",
    "    return resultado\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 4, 3, 3, 4, 5, 3, 4, 5, 3, 3, 4, 8, 4, 4, 3, 8, 4, 8, 3, 4, 4, 4, 4, 8, 3, 3, 5, 3, 5, 3, 4, 4, 3, 3, 5, 4, 3, 4, 8, 4, 3, 4, 8, 4, 8]\n"
     ]
    }
   ],
   "source": [
    "# Encontramos los valores outliers del dataset para la variable \"SibSp\"\n",
    "\n",
    "aux = titanicTraindata['SibSp']\n",
    "aux2 = (limites_outliers (aux))\n",
    "aux2 = titanicTraindata.loc[ (titanicTraindata['SibSp'] < aux2[0]) | (titanicTraindata['SibSp'] > aux2[1]) ] \n",
    "\n",
    "print (list(aux2.SibSp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 1, 5, 1, 1, 5, 2, 2, 1, 1, 2, 2, 2, 1, 2, 2, 2, 3, 2, 2, 1, 1, 1, 1, 2, 1, 1, 2, 2, 1, 2, 2, 2, 1, 2, 1, 1, 2, 1, 4, 1, 1, 1, 1, 2, 2, 1, 2, 1, 1, 1, 2, 1, 1, 2, 2, 2, 1, 1, 2, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 2, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 4, 1, 1, 2, 2, 2, 2, 2, 1, 1, 1, 2, 2, 1, 1, 2, 2, 3, 4, 1, 2, 1, 1, 2, 1, 2, 1, 2, 1, 1, 2, 2, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 1, 1, 2, 1, 4, 1, 1, 2, 1, 2, 1, 1, 2, 5, 2, 1, 1, 1, 2, 1, 5, 2, 1, 1, 1, 2, 1, 6, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 3, 2, 1, 1, 1, 1, 2, 1, 2, 3, 1, 2, 1, 2, 2, 1, 1, 2, 1, 2, 1, 2, 1, 1, 1, 2, 1, 1, 2, 1, 2, 1, 1, 1, 1, 3, 2, 1, 1, 1, 1, 5, 2]\n"
     ]
    }
   ],
   "source": [
    "# Encontramos los valores outliers del dataset para la variable \"Parch\"  \n",
    "    \n",
    "campo = 'Parch'\n",
    "aux = titanicTraindata[campo]\n",
    "aux2 = (limites_outliers (aux))\n",
    "                      \n",
    "aux2 = titanicTraindata.loc[ (titanicTraindata[campo] < aux2[0]) | (titanicTraindata[campo] > aux2[1]) ] \n",
    "\n",
    "print (list(aux2[campo]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[71.2833, 263.0, 146.5208, 82.1708, 76.7292, 80.0, 83.475, 73.5, 263.0, 77.2875, 247.5208, 73.5, 77.2875, 79.2, 66.6, 69.55, 69.55, 146.5208, 69.55, 113.275, 76.2917, 90.0, 83.475, 90.0, 79.2, 86.5, 512.3292, 79.65, 153.4625, 135.6333, 77.9583, 78.85, 91.0792, 151.55, 247.5208, 151.55, 110.8833, 108.9, 83.1583, 262.375, 164.8667, 134.5, 69.55, 135.6333, 153.4625, 133.65, 66.6, 134.5, 263.0, 75.25, 69.3, 135.6333, 82.1708, 211.5, 227.525, 73.5, 120.0, 113.275, 90.0, 120.0, 263.0, 81.8583, 89.1042, 91.0792, 90.0, 78.2667, 151.55, 86.5, 108.9, 93.5, 221.7792, 106.425, 71.0, 106.425, 110.8833, 227.525, 79.65, 110.8833, 79.65, 79.2, 78.2667, 153.4625, 77.9583, 69.3, 76.7292, 73.5, 113.275, 133.65, 73.5, 512.3292, 76.7292, 211.3375, 110.8833, 227.525, 151.55, 227.525, 211.3375, 512.3292, 78.85, 262.375, 71.0, 86.5, 120.0, 77.9583, 211.3375, 79.2, 69.55, 120.0, 93.5, 80.0, 83.1583, 69.55, 89.1042, 164.8667, 69.55, 83.1583]\n"
     ]
    }
   ],
   "source": [
    "# Encontramos los valores outliers del dataset para la variable \"Fare\"  \n",
    "\n",
    "campo = 'Fare'\n",
    "aux = titanicTraindata[campo]\n",
    "aux2 = (limites_outliers (aux))\n",
    "aux2 = titanicTraindata.loc[ (titanicTraindata[campo] < aux2[0]) | (titanicTraindata[campo] > aux2[1]) ] \n",
    "\n",
    "print (list(aux2[campo]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 14, 4, 58, 14, 2, 8, 66, 14, 3, 4, 7, 65, 5, 11, 4, 0, 59, 71, 14, 70, 2, 12, 12, 9, 1, 9, 61, 4, 1, 9, 1, 4, 3, 58, 2, 59, 5, 8, 62, 3, 58, 63, 7, 65, 2, 0, 61, 2, 3, 60, 3, 1, 1, 3, 10, 14, 64, 4, 13, 5, 65, 0, 2, 9, 63, 58, 9, 71, 2, 7, 9, 11, 64, 8, 62, 62, 60, 4, 61, 80, 9, 2, 0, 58, 70, 14, 60, 14, 4, 60, 6, 11, 70, 4, 6, 0, 5, 13, 8, 1, 11, 0, 6, 10, 2, 1, 62, 0, 4, 74, 9, 4]\n"
     ]
    }
   ],
   "source": [
    "# Encontramos los valores outliers del dataset para la variable \"Age\"  \n",
    "\n",
    "campo = 'Age'\n",
    "aux = titanicTraindata[campo]\n",
    "aux2 = (limites_outliers (aux))\n",
    "aux2 = titanicTraindata.loc[ (titanicTraindata[campo] < aux2[0]) | (titanicTraindata[campo] > aux2[1]) ] \n",
    "\n",
    "print (list(aux2[campo]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(4) TESTS DE NORMALIDAD NO PARAMÉTRICOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.718337893486023, 3.3958319924210316e-36)\n",
      "(0.98072749376297, 1.8490181608044054e-09)\n",
      "(0.5129655003547668, 5.74532370373175e-44)\n",
      "(0.5328145027160645, 2.382207389352189e-43)\n",
      "(0.5218914747238159, 1.0789998175301091e-43)\n"
     ]
    }
   ],
   "source": [
    "' Test de normalidad mediante el test de Shapiro-Wilk'\n",
    "\n",
    "\n",
    "from scipy.stats import shapiro\n",
    "\n",
    "\n",
    "# Test de normalidad de la variable Pclass Resultado de (Prob,  \"p\" o singificancia)\n",
    "\n",
    "x1 = shapiro(titanicTraindata.Pclass)\n",
    "\n",
    "print (x1)\n",
    "\n",
    "# Test de normalidad de la variable Age Resultado de (Prob,  \"p\" o singificancia)\n",
    "\n",
    "x2 = shapiro(titanicTraindata.Age)\n",
    "print (x2)\n",
    "\n",
    "# Test de normalidad de la variable SibSp Resultado de (Prob,  \"p\" o singificancia)\n",
    "\n",
    "x3 = shapiro(titanicTraindata.SibSp)\n",
    "print (x3)\n",
    "\n",
    "# Test de normalidad de la variable Parch Resultado de (Prob,  \"p\" o singificancia)\n",
    "\n",
    "x4 = shapiro(titanicTraindata.Parch)\n",
    "print (x4)\n",
    "\n",
    "# Test de normalidad de la variable Fare Resultado de (Prob,  \"p\" o singificancia)\n",
    "\n",
    "x5 = shapiro(titanicTraindata.Fare)\n",
    "print (x5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(5) TEST VARIANCIAS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FlignerResult(statistic=1.8903305462894795, pvalue=0.16916464402951714)\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import fligner as FK \n",
    "\n",
    "# En el meteodo encontrado en la libreria hemos podido comprobar que no se admiten campos no numéricos.\n",
    "# Por ello los campos tipo STR  en 'Sex' , los convertimos en numéricos.\n",
    "\n",
    "Sex_int = titanicTraindata.Sex\n",
    "\n",
    "Sex_int = Sex_int.replace('female',0)\n",
    "Sex_int = Sex_int.replace('male',1)\n",
    "\n",
    "x1 = FK(Sex_int, titanicTraindata.Survived )\n",
    "\n",
    "print (x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FlignerResult(statistic=4.124670954313547, pvalue=0.042262238657693296)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# En el meteodo encontrado en la libreria hemos podido comprobar que no se admiten campos no numéricos.\n",
    "# Por ello los campos tipo STR  en 'Embarked' , los convertimos en numéricos.\n",
    "\n",
    "Embarked_int = titanicTraindata.Embarked\n",
    "\n",
    "Embarked_int = Embarked_int.replace('C',0)\n",
    "Embarked_int = Embarked_int.replace('Q',1)\n",
    "Embarked_int = Embarked_int.replace('S',2)\n",
    "\n",
    "x1 = FK(Embarked_int, titanicTraindata.Survived )\n",
    "\n",
    "print (x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FlignerResult(statistic=89.50879252308928, pvalue=3.0527868978165962e-21)\n"
     ]
    }
   ],
   "source": [
    "Pclass_int = titanicTraindata.Pclass\n",
    "\n",
    "x1 = FK(Pclass_int, titanicTraindata.Survived )\n",
    "\n",
    "print (x1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(6) CALCULOS DE CORRELACION DE SPEARMAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SpearmanrResult(correlation=-0.03319443011904244, pvalue=0.3223095243860028)\n"
     ]
    }
   ],
   "source": [
    "# Aplicamos la correlación de Spearman.\n",
    "# Hipótesis nula: No existe correlación significativa entre ambas variables.\n",
    "\n",
    "from scipy.stats import spearmanr as SPR\n",
    "\n",
    "x1 = SPR(titanicTraindata.Age , titanicTraindata.Survived )\n",
    "\n",
    "print (x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SpearmanrResult(correlation=0.08887948468090501, pvalue=0.007941431285733533)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "x1 = SPR(titanicTraindata.SibSp , titanicTraindata.Survived )\n",
    "\n",
    "print (x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SpearmanrResult(correlation=0.13826563286545587, pvalue=3.453591460380432e-05)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "x1 = SPR(titanicTraindata.Parch , titanicTraindata.Survived )\n",
    "\n",
    "print (x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SpearmanrResult(correlation=0.32373613944480834, pvalue=3.471227970207005e-23)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "x1 = SPR(titanicTraindata.Fare , titanicTraindata.Survived )\n",
    "\n",
    "print (x1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(7) TEST DE CHI PARA VARIABLE Sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sex       female  male\n",
      "Survived              \n",
      "0             81   468\n",
      "1            233   109\n",
      "--------------------\n",
      "El valor del Estadístico de comprobación es\n",
      "260.71702016732104\n",
      "--------------------\n",
      "La 'p' calculada es:\n",
      "1.1973570627755645e-58\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import chi2_contingency as chi2\n",
    "\n",
    "\n",
    "# Aplicamos un test de ChiSq.\n",
    "# Hipótesis nula: No existe correlación significativa entre ambas variables Sex / Survived\n",
    "# Para ello empleamos la lista numérica calculada anteriormente Sex_int\n",
    "# Obtenemos la tabla de frecuencias\n",
    "\n",
    "contingency_table = pd.crosstab( titanicTraindata.Survived, titanicTraindata.Sex )\n",
    "\n",
    "print ( contingency_table )\n",
    "\n",
    "x1 = chi2( contingency_table )\n",
    "\n",
    "print (\"--------------------\")\n",
    "print (\"El valor del Estadístico de comprobación es\")\n",
    "print ( x1[0])\n",
    "print (\"--------------------\")\n",
    "print (\"La 'p' calculada es:\")\n",
    "print ( x1[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(8) TEST DE WILCOX "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57806.5 2.2767385896251186e-22\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import mannwhitneyu as mann\n",
    "\n",
    "# Seleccionamos el grupo de pasajeros que no sobrevivieron \n",
    "\n",
    "titanicTraindata_died = titanicTraindata.loc[titanicTraindata['Survived'] == 0]\n",
    "fare_died = titanicTraindata_died.Fare\n",
    "\n",
    "titanicTraindata_surv = titanicTraindata.loc[titanicTraindata['Survived'] == 1] \n",
    "fare_surv = titanicTraindata_surv.Fare\n",
    "\n",
    "\n",
    "stat, p = mann(x= fare_died, y= fare_surv, use_continuity= True, alternative=\"less\")\n",
    "\n",
    "print (stat, p)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(9) DETERMINACION DE UNA FORMULA DE REGRESION LOGISTICA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = titanicTraindata[['Survived']]\n",
    "X = titanicTraindata[['Fare','Sex','Pclass','Age','SibSp','Embarked']]\n",
    "\n",
    "\n",
    "# Tenemos que tratar la variables categoricas y las convertimos en numericas.\n",
    "\n",
    "X = X.replace('female',0)\n",
    "X = X.replace('male',1)\n",
    "\n",
    "X = X.replace('C',0)\n",
    "X = X.replace('Q',1)\n",
    "X = X.replace('S',2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.495996\n",
      "         Iterations 6\n",
      "                         Results: Logit\n",
      "=================================================================\n",
      "Model:              Logit            Pseudo R-squared: 0.255     \n",
      "Dependent Variable: Survived         AIC:              895.8653  \n",
      "Date:               2020-06-04 13:29 BIC:              924.6193  \n",
      "No. Observations:   891              Log-Likelihood:   -441.93   \n",
      "Df Model:           5                LL-Null:          -593.33   \n",
      "Df Residuals:       885              LLR p-value:      2.5168e-63\n",
      "Converged:          1.0000           Scale:            1.0000    \n",
      "No. Iterations:     6.0000                                       \n",
      "------------------------------------------------------------------\n",
      "              Coef.   Std.Err.     z      P>|z|    [0.025   0.975]\n",
      "------------------------------------------------------------------\n",
      "Fare          0.0172    0.0028    6.0364  0.0000   0.0116   0.0227\n",
      "Sex          -2.2518    0.1751  -12.8604  0.0000  -2.5950  -1.9086\n",
      "Pclass        0.0253    0.0756    0.3355  0.7373  -0.1227   0.1734\n",
      "Age           0.0067    0.0055    1.2138  0.2248  -0.0041   0.0176\n",
      "SibSp        -0.3121    0.0922   -3.3858  0.0007  -0.4927  -0.1314\n",
      "Embarked      0.1030    0.1055    0.9760  0.3290  -0.1038   0.3097\n",
      "=================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "\n",
    "# Realizamos una primera prueba por Statsmodels que nos da un resumen interesante del contenido del modelo.\n",
    "logit2 = sm.Logit(y,X)\n",
    "result2 = logit2.fit()\n",
    "print (result2.summary2())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression as LGR\n",
    "\n",
    "\n",
    "# Realizamos el otro métido por Sklearn.\n",
    "logit = LGR()\n",
    "result=logit.fit(X,y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[470  79]\n",
      " [ 99 243]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.86      0.84       549\n",
      "           1       0.75      0.71      0.73       342\n",
      "\n",
      "    accuracy                           0.80       891\n",
      "   macro avg       0.79      0.78      0.79       891\n",
      "weighted avg       0.80      0.80      0.80       891\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Realizamos la predicción de probabilidades.\n",
    "y_pred = result.predict(X)\n",
    "\n",
    "\n",
    "confusion_matrix = confusion_matrix(y, y_pred)\n",
    "print((confusion_matrix))\n",
    "\n",
    "\n",
    "print(classification_report(y, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10ca24f60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "logit_roc_auc = roc_auc_score(y, result.predict(X))\n",
    "fpr, tpr, thresholds = roc_curve(y, result.predict_proba(X)[:,1])\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label='Logistic Regression (area = %0.2f)' % logit_roc_auc)\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig('Log_ROC')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GUARDAMOS EL CSV RESULTADO\n",
    "\n",
    "titanicTraindata.to_csv('titanicTraindata_python.csv')  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
